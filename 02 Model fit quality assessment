#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Model Fit Quality Assessment for Two-Stage Diagenetic Model
===========================================================

This script evaluates the goodness-of-fit between the two-stage diagenetic
model and observed trace element data by calculating Euclidean distances
from sample points to theoretical model pathways.

Reference:
    Banner, J.L., & Hanson, G.N. (1990). Calculation of simultaneous isotopic
    and trace element variations during water-rock interaction with applications
    to carbonate diagenesis. Geochimica et Cosmochimica Acta, 54(11), 3123-3137.

Input:
    CSV file with columns: 'Mn/Sr', 'Mn/Fe', 'Sr/Ca'

Output:
    - High-resolution fit quality histogram and cumulative curve (300 DPI)
    - Statistical report on model performance

Author: [Fei Li]
Date: 2026
License: MIT
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
import warnings
import sys

warnings.filterwarnings('ignore')

# ==============================================================================
# MODEL PARAMETERS
# ==============================================================================

# Early diagenesis stage (shallow burial, oxic to suboxic conditions)
STAGE1_PARAMS = {
    'name': 'Early Diagenesis',
    'Cs0': {'Sr': 9874.0, 'Mn': 0.735, 'Fe': 164.0, 'Ca': 380000.0},
    'Cf0': {'Sr': 0.15, 'Mn': 6.0, 'Fe': 120.0},
    'D': {'Sr': 0.08, 'Mn': 18.0, 'Fe': 18.0},
    'N_range': [0.01, 10.0]  # Water/rock ratio range
}

# Late diagenesis stage (deep burial, reducing conditions)
STAGE2_PARAMS = {
    'name': 'Late Diagenesis',
    'Cs0': {'Sr': 5000.0, 'Mn': 25.0, 'Fe': 140.0, 'Ca': 380000.0},
    'Cf0': {'Sr': 0.05, 'Mn': 15.0, 'Fe': 200.0},
    'D': {'Sr': 0.04, 'Mn': 25.0, 'Fe': 22.0},
    'N_range': [0.5, 200.0]
}

# Fit quality thresholds
FIT_THRESHOLDS = {
    'excellent': 0.05,
    'good': 0.10,
    'acceptable': 0.15
}

# ==============================================================================
# COMPUTATIONAL FUNCTIONS
# ==============================================================================

def calculate_concentrations(Cs0, Cf0, D, N_values):
    """
    Calculate theoretical solid phase concentrations using Banner & Hanson (1990) model.
    
    Parameters:
    -----------
    Cs0 : dict
        Initial solid phase concentrations
    Cf0 : dict
        Initial fluid phase concentrations
    D : dict
        Partition coefficients
    N_values : array
        Water/rock ratio values
        
    Returns:
    --------
    DataFrame with Sr, Mn, Fe concentrations
    """
    results = {'Sr': [], 'Mn': [], 'Fe': []}
    
    for N in N_values:
        s_Sr = (D['Sr'] * (Cs0['Sr'] + N * Cf0['Sr'])) / (D['Sr'] + N)
        s_Mn = (D['Mn'] * (Cs0['Mn'] + N * Cf0['Mn'])) / (D['Mn'] + N)
        s_Fe = (D['Fe'] * (Cs0['Fe'] + N * Cf0['Fe'])) / (D['Fe'] + N)
        
        results['Sr'].append(s_Sr)
        results['Mn'].append(s_Mn)
        results['Fe'].append(s_Fe)
    
    return pd.DataFrame(results)


def get_ternary_coords(mn_sr, mn_fe, sr_ca_scaled):
    """
    Convert trace element ratios to Cartesian coordinates for ternary plot.
    
    Parameters:
    -----------
    mn_sr : array
        Mn/Sr ratios
    mn_fe : array
        Mn/Fe ratios
    sr_ca_scaled : array
        Sr/Ca ratios multiplied by 300
        
    Returns:
    --------
    x, y : arrays
        Cartesian coordinates
    """
    total = mn_sr + mn_fe + sr_ca_scaled
    norm_top = mn_sr / total
    norm_right = mn_fe / total
    
    x = 0.5 * norm_top + 1.0 * norm_right
    y = (np.sqrt(3) / 2) * norm_top
    
    return x, y


def calculate_deviations(df, stages_params):
    """
    Calculate Euclidean distance from each sample to nearest model pathway.
    
    Parameters:
    -----------
    df : DataFrame
        Sample data with Mn/Sr, Mn/Fe, Sr/Ca columns
    stages_params : list
        List of stage parameter dictionaries
        
    Returns:
    --------
    array of minimum distances for each sample
    """
    print(f"\n[INFO] Calculating fit quality for {len(df)} samples...")
    
    distances = []
    model_curves = []
    
    # Pre-calculate high-resolution model curves
    for stage in stages_params:
        N_values = np.logspace(
            np.log10(stage['N_range'][0]),
            np.log10(stage['N_range'][1]),
            1000
        )
        
        sim_df = calculate_concentrations(
            stage['Cs0'], stage['Cf0'], stage['D'], N_values
        )
        
        m_mn_sr = sim_df['Mn'] / sim_df['Sr']
        m_mn_fe = sim_df['Mn'] / sim_df['Fe']
        m_sr_ca = (sim_df['Sr'] / stage['Cs0']['Ca']) * 300
        
        mx, my = get_ternary_coords(m_mn_sr.values, m_mn_fe.values, m_sr_ca.values)
        model_curves.append((mx, my))
    
    # Calculate minimum distance for each sample
    for i in range(len(df)):
        d_mn_sr = df.iloc[i]['Mn/Sr']
        d_mn_fe = df.iloc[i]['Mn/Fe']
        d_sr_ca = df.iloc[i]['Sr/Ca'] * 300
        
        dx, dy = get_ternary_coords(
            np.array([d_mn_sr]), np.array([d_mn_fe]), np.array([d_sr_ca])
        )
        
        min_dist = float('inf')
        for mx, my in model_curves:
            dists = np.sqrt((mx - dx[0])**2 + (my - dy[0])**2)
            local_min = np.min(dists)
            if local_min < min_dist:
                min_dist = local_min
        
        distances.append(min_dist)
    
    return np.array(distances)


# ==============================================================================
# VISUALIZATION FUNCTIONS
# ==============================================================================

def plot_histogram(ax, df, deviations):
    """
    Generate histogram panel showing distribution of fit quality.
    
    Parameters:
    -----------
    ax : matplotlib axis
        Axis for plotting
    df : DataFrame
        Sample data with cluster assignments
    deviations : array
        Distance values for each sample
    """
    cluster0_dev = deviations[df['cluster'] == 0]
    cluster1_dev = deviations[df['cluster'] == 1]
    
    bins = np.linspace(0, max(0.25, deviations.max()), 30)
    
    ax.hist(cluster0_dev, bins=bins, alpha=0.6, color='royalblue',
           edgecolor='black', lw=0.5, label='Cluster 0 (Low Alteration)')
    ax.hist(cluster1_dev, bins=bins, alpha=0.6, color='limegreen',
           edgecolor='black', lw=0.5, label='Cluster 1 (High Alteration)')
    
    # Threshold lines
    ax.axvline(FIT_THRESHOLDS['excellent'], color='green', ls='--', lw=2,
              label=f"Excellent (<{FIT_THRESHOLDS['excellent']})")
    ax.axvline(FIT_THRESHOLDS['good'], color='orange', ls='--', lw=2,
              label=f"Good (<{FIT_THRESHOLDS['good']})")
    ax.axvline(FIT_THRESHOLDS['acceptable'], color='red', ls='--', lw=2,
              label=f"Acceptable (<{FIT_THRESHOLDS['acceptable']})")
    
    # Calculate statistics
    total = len(deviations)
    excellent = np.sum(deviations < FIT_THRESHOLDS['excellent'])
    good = np.sum(deviations < FIT_THRESHOLDS['good'])
    
    stats_text = (f"Total Samples: {total}\n"
                 f"Mean RMSE: {np.mean(deviations):.4f}\n"
                 f"Excellent Fit: {excellent/total*100:.1f}%\n"
                 f"Good Fit: {good/total*100:.1f}%")
    
    ax.text(0.95, 0.95, stats_text, transform=ax.transAxes,
           ha='right', va='top',
           bbox=dict(boxstyle='round', facecolor='white', alpha=0.9),
           fontsize=10)
    
    ax.set_xlabel('Model Deviation (Euclidean Distance)', fontweight='bold')
    ax.set_ylabel('Frequency', fontweight='bold')
    ax.set_title('(A) Distribution of Fit Quality', fontweight='bold', loc='left')
    ax.legend(loc='upper right', fontsize=9)
    ax.grid(axis='y', alpha=0.3, ls='--')


def plot_cumulative(ax, df, deviations):
    """
    Generate cumulative curve panel showing sorted fit performance.
    
    Parameters:
    -----------
    ax : matplotlib axis
        Axis for plotting
    df : DataFrame
        Sample data with cluster assignments
    deviations : array
        Distance values for each sample
    """
    sorted_idx = np.argsort(deviations)
    sorted_dev = deviations[sorted_idx]
    sorted_clusters = df.iloc[sorted_idx]['cluster'].values
    
    x = np.arange(len(sorted_dev))
    colors = ['royalblue' if c == 0 else 'limegreen' for c in sorted_clusters]
    
    ax.scatter(x, sorted_dev, c=colors, s=15, alpha=0.7, edgecolors='none')
    
    # Threshold lines
    ax.axhline(FIT_THRESHOLDS['excellent'], color='green', ls='--', alpha=0.5)
    ax.axhline(FIT_THRESHOLDS['good'], color='orange', ls='--', alpha=0.5)
    ax.axhline(FIT_THRESHOLDS['acceptable'], color='red', ls='--', alpha=0.5)
    
    ax.text(0, FIT_THRESHOLDS['excellent'] + 0.002, 'Excellent',
           color='green', fontsize=8, fontweight='bold')
    ax.text(0, FIT_THRESHOLDS['good'] + 0.002, 'Good',
           color='orange', fontsize=8, fontweight='bold')
    
    ax.set_xlabel('Sample Rank (Sorted by Fit Quality)', fontweight='bold')
    ax.set_ylabel('Deviation Magnitude', fontweight='bold')
    ax.set_title('(B) Cumulative Fit Performance', fontweight='bold', loc='left')
    
    from matplotlib.lines import Line2D
    legend_elements = [
        Line2D([0], [0], marker='o', color='w', markerfacecolor='royalblue',
              markersize=8, label='Cluster 0'),
        Line2D([0], [0], marker='o', color='w', markerfacecolor='limegreen',
              markersize=8, label='Cluster 1')
    ]
    ax.legend(handles=legend_elements, loc='upper left')
    ax.grid(alpha=0.3, ls='--')


# ==============================================================================
# MAIN EXECUTION
# ==============================================================================

def main(csv_file, output_file='fit_quality_assessment.png'):
    """
    Main execution function.
    
    Parameters:
    -----------
    csv_file : str
        Path to input CSV file
    output_file : str
        Path to output figure file
    """
    print("\n" + "="*70)
    print("MODEL FIT QUALITY ASSESSMENT")
    print("="*70)
    
    try:
        # Load data
        print(f"\n[INFO] Loading data from: {csv_file}")
        df = pd.read_csv(csv_file)
        
        # Validate columns
        required_cols = ['Mn/Sr', 'Mn/Fe', 'Sr/Ca']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            raise ValueError(f"Missing required columns: {missing_cols}")
        
        print(f"[INFO] Loaded {len(df)} samples successfully")
        
        # Clustering for visualization grouping
        print("\n[INFO] Performing cluster analysis...")
        kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
        df['cluster'] = kmeans.fit_predict(df[['Mn/Sr', 'Mn/Fe', 'Sr/Ca']].values)
        
        # Calculate deviations
        stages = [STAGE1_PARAMS, STAGE2_PARAMS]
        deviations = calculate_deviations(df, stages)
        
        # Print statistics
        print("\n" + "="*70)
        print("FIT QUALITY STATISTICS")
        print("="*70)
        print(f"Mean RMSE: {np.mean(deviations):.4f}")
        print(f"Median RMSE: {np.median(deviations):.4f}")
        print(f"Std Dev: {np.std(deviations):.4f}")
        print(f"\nExcellent Fit (<{FIT_THRESHOLDS['excellent']}): "
              f"{np.sum(deviations < FIT_THRESHOLDS['excellent'])/len(deviations)*100:.1f}%")
        print(f"Good Fit (<{FIT_THRESHOLDS['good']}): "
              f"{np.sum(deviations < FIT_THRESHOLDS['good'])/len(deviations)*100:.1f}%")
        print(f"Acceptable Fit (<{FIT_THRESHOLDS['acceptable']}): "
              f"{np.sum(deviations < FIT_THRESHOLDS['acceptable'])/len(deviations)*100:.1f}%")
        print("="*70)
        
        # Generate plot
        print(f"\n[INFO] Generating fit quality assessment plot...")
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))
        fig.suptitle('Model Fit Quality Assessment',
                    fontsize=16, fontweight='bold', y=0.98)
        
        plot_histogram(axes[0], df, deviations)
        plot_cumulative(axes[1], df, deviations)
        
        plt.tight_layout()
        plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')
        
        print(f"[INFO] Figure saved: {output_file}")
        print(f"[INFO] Resolution: 300 DPI (publication-ready)\n")
        
        plt.close()
        
    except Exception as e:
        print(f"\n[ERROR] {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("\nUsage: python model_fit_quality_assessment.py <input.csv> [output.png]")
        print("\nExample:")
        print("  python model_fit_quality_assessment.py samples.csv fit_quality.png")
        sys.exit(1)
    
    csv_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else 'fit_quality_assessment.png'
    
    main(csv_file, output_file)
